{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple, defaultdict\n",
    "from collections.abc import Iterable\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jtplot.style()\n",
    "# plt.xkcd()\n",
    "\n",
    "def filter_experiments(experiments, mask):\n",
    "    # Mask is a namedtuple that has None for fields that are to be ignored\n",
    "    mask_base = set(filter(lambda y: not isinstance(y[1], tuple), \n",
    "                           filter(lambda x: x[1], mask._asdict().items())))\n",
    "    mask_permutes = set(filter(lambda y: isinstance(y[1], tuple),\n",
    "                              filter(lambda x: x[1], mask._asdict().items())))\n",
    "    \n",
    "    # Delta is the permuting parameter expansions\n",
    "    delta = list(map(lambda x: set(product((x[0],), x[1])), mask_permutes))\n",
    "    permutations = [x.union(mask_base) for x in list(map(lambda x: set(x), product(*delta)))]\n",
    "    \n",
    "    # All of the experiments that match the filter(s)\n",
    "    exps = list(map(lambda x: set(filter(lambda y: x <= set(y._asdict().items()), experiments)), permutations))\n",
    "    \n",
    "    # Collapse all of the experiments into a set and return it\n",
    "    return reduce(lambda x, y: x.union(y), exps)\n",
    "\n",
    "def filter_anomalies(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    \n",
    "    return [x for x in data if (mean - 2 * std) < x < (mean + 2 * std)]\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), st.sem(a)\n",
    "    h = se * st.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h\n",
    "\n",
    "def median_mean_confidence_interval(data, confidence=0.95):\n",
    "    m, h = mean_confidence_interval(data, confidence)\n",
    "    return np.median(data), m, h\n",
    "\n",
    "def aggregate_results(results_dir):\n",
    "    control_files = [x for x in os.listdir(str(results_dir)) if 'control_' in x]\n",
    "    results_files = [x for x in os.listdir(str(results_dir)) if 'results_' in x]\n",
    "    \n",
    "    # Aggregate the control data\n",
    "    control = {}\n",
    "    for f in control_files:\n",
    "        file_path = Path(results_dir, f)\n",
    "        with open(str(file_path), 'rb') as handle:\n",
    "            file_dict = pickle.load(handle)\n",
    "            control.update(file_dict)\n",
    "            \n",
    "    # Aggregate the experiment results\n",
    "    experiments = {}\n",
    "    for f in results_files:\n",
    "        file_path = Path(results_dir, f)\n",
    "        with open(str(file_path), 'rb') as handle:\n",
    "            file_dict = pickle.load(handle)\n",
    "            experiments.update(file_dict)\n",
    "            \n",
    "    return control, experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_control(file_path):\n",
    "    # Parse the COOJA.testlog file\n",
    "    logfile = open(file_path, 'r').readlines()\n",
    "    end_tick_re = re.compile(r'^(?P<tick>\\d+)\\ all\\ motes\\ converged,\\ closing\\ sim$')\n",
    "    end_tick = None\n",
    "\n",
    "    for line in logfile:\n",
    "        match = end_tick_re.match(line)\n",
    "\n",
    "        if match:\n",
    "            end_tick = int(match.group('tick'))\n",
    "\n",
    "    return end_tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_coverage(file_path):\n",
    "    # Parse the COOJA.testlog file\n",
    "    logfile = open(file_path, 'r').readlines()\n",
    "    motes_re = re.compile(r'Nodes covered: (?P<n>\\d+) at time (?P<t>\\d+)')\n",
    "    \n",
    "    coverage_raw = []\n",
    "    \n",
    "    for line in logfile:\n",
    "        match = motes_re.match(line)\n",
    "        \n",
    "        if match:\n",
    "            coverage_raw.append(match.groupdict())\n",
    "            \n",
    "    coverage_raw = list(map(lambda x: ((int(x['t'])/1e6), 100*(int(x['n'])/21**2)), coverage_raw))\n",
    "    coverage_raw = sorted(coverage_raw, key=lambda x: x[0])\n",
    "    \n",
    "    return coverage_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_coverage(results_path, results, control, exp_type, \n",
    "                   filter_params={}, **kwargs):\n",
    "    filtered_result = list(filter_experiments(results.keys(), exp_type(**filter_params)))[0]\n",
    "    results_dirs = list(filter(lambda x: x.startswith(str(filtered_result)), os.listdir(str(results_path))))\n",
    "    \n",
    "    results_raw = []\n",
    "    results_dicts = []\n",
    "    for result_dir in results_dirs:\n",
    "        cooja_log = Path(results_path, result_dir, 'COOJA.testlog')\n",
    "        r = process_coverage(str(cooja_log))\n",
    "        results_raw.append(r)\n",
    "        results_dicts.append(dict(r))\n",
    "        \n",
    "    timeslots = set()\n",
    "    for results in results_raw:\n",
    "        timeslots = timeslots.union(set(map(lambda x: x[0], results)))\n",
    "        \n",
    "    timeslots = sorted(timeslots)\n",
    "    data_raw = np.zeros((len(timeslots), len(results_raw)), dtype=float)\n",
    "    data_processed = []\n",
    "    \n",
    "    for i in range(len(timeslots)):\n",
    "        col = data_raw[i-1] if i > 1 else data_raw[0]\n",
    "        t = timeslots[i]\n",
    "        \n",
    "        for j in range(len(results_dicts)):\n",
    "            col[j] = results_dicts[j].get(t, col[j])\n",
    "            \n",
    "        median, mean, ci = median_mean_confidence_interval(col)\n",
    "        data_raw[i] = col\n",
    "        data_processed.append((t, median, mean, ci, np.amin(col), np.amax(col)))\n",
    "    \n",
    "    # Graph the data\n",
    "    figsize = kwargs.get('figsize', (15, 10))\n",
    "    fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    if kwargs.get('plot_sims', False):\n",
    "        for i, results in enumerate(results_raw):\n",
    "            x_temp = list(map(lambda x: x[0], results))\n",
    "            y_temp = list(map(lambda x: x[1], results))\n",
    "            axes.plot(x_temp, y_temp, alpha=0.3)\n",
    "    \n",
    "    x_axis = list(map(lambda x: x[0], data_processed))\n",
    "    y_axis = list(map(lambda x: x[2], data_processed)) # Graph the median\n",
    "    \n",
    "    axes.grid(linestyle='--')\n",
    "    axes.plot(x_axis, y_axis, label='Median message coverage')\n",
    "    legend_loc = kwargs.get('legend_loc', 'best')\n",
    "    axes.legend(loc=legend_loc)\n",
    "    \n",
    "    # Config via. KWargs\n",
    "    if kwargs.get('figtitle'):\n",
    "        fig.suptitle(kwargs.get('figtitle'))\n",
    "    if kwargs.get('xlabel'):\n",
    "        axes.set_xlabel(kwargs.get('xlabel'))\n",
    "    if kwargs.get('ylabel'):\n",
    "        axes.set_ylabel(kwargs.get('ylabel'))\n",
    "    if kwargs.get('title'):\n",
    "        axes.set_title(kwargs.get('title'))\n",
    "    if kwargs.get('ylim'):\n",
    "        axes.set_ylim(*kwargs.get('ylim'))\n",
    "    if kwargs.get('xlim'):\n",
    "        axes.set_xlim(*kwargs.get('xlim'))\n",
    "    # Save the file\n",
    "    if kwargs.get('filename'):\n",
    "        fig.savefig(fname=kwargs.get('filename'), dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_data(x_key, y_key, results, control, exp_type, filter_params={}, \n",
    "               control_params=None, **kwargs):\n",
    "    filter_params[x_key] = None  # Set the X value to none for X-axis\n",
    "    \n",
    "    if not control_params:\n",
    "        control_params = dict([(key, None) for key in exp_type._fields])\n",
    "    filtered_control = filter_experiments(control.keys(), exp_type(**control_params))\n",
    "    processed_control = []\n",
    "    for exp in filtered_control:\n",
    "        exp_data = control[exp]\n",
    "        exp_data = list(map(lambda x: float(x), \n",
    "                            filter(lambda x: x, map(lambda x: x.get(y_key), exp_data))))\n",
    "        exp_mean, exp_ci = mean_confidence_interval(exp_data)\n",
    "        \n",
    "        processed_control.append((exp_mean, exp_ci))\n",
    "    \n",
    "    filtered_results = filter_experiments(results.keys(), exp_type(**filter_params))\n",
    "    processed_results = []\n",
    "    for exp in filtered_results:\n",
    "        exp_data = results[exp]\n",
    "        exp_data = list(map(lambda x: float(x), \n",
    "                            filter(lambda x: x, map(lambda x: x.get(y_key), exp_data))))\n",
    "        exp_mean, exp_ci = mean_confidence_interval(exp_data)\n",
    "        \n",
    "        processed_results.append((getattr(exp, x_key), (exp_mean, exp_ci)))\n",
    "    \n",
    "    # Sort the x axis in ascending order\n",
    "    processed_results = sorted(processed_results, key=lambda x: x[0])\n",
    "    control_value = processed_control[0][0]\n",
    "    \n",
    "    # Graph the data\n",
    "    figsize = kwargs.get('figsize', (15, 10))\n",
    "    fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    x_axis, data = tuple(list(map(list, zip(*processed_results))))\n",
    "    axes.set_xticks(x_axis)\n",
    "    axes.grid(linestyle='--')\n",
    "    axes.errorbar(x_axis, *list(map(list, zip(*data))),\n",
    "                 marker='^', color='royalblue', ecolor='orange', capsize=4)\n",
    "    axes.axhline(control_value, color='orangered', linestyle='--')\n",
    "    # Config via. KWargs\n",
    "    if kwargs.get('figtitle'):\n",
    "        fig.suptitle(kwargs.get('figtitle'))\n",
    "    if kwargs.get('xlabel'):\n",
    "        axes.set_xlabel(kwargs.get('xlabel'))\n",
    "    if kwargs.get('ylabel'):\n",
    "        axes.set_ylabel(kwargs.get('ylabel'))\n",
    "    if kwargs.get('title'):\n",
    "        axes.set_title(kwargs.get('title'))\n",
    "    if kwargs.get('ylim'):\n",
    "        axes.set_ylim(*kwargs.get('ylim'))\n",
    "    if kwargs.get('xlim'):\n",
    "        axes.set_xlim(*kwargs.get('xlim'))\n",
    "        \n",
    "    # Control label padding\n",
    "    left, right = axes.get_xlim()\n",
    "    right_pad = 1 * ((right - left) / 100)\n",
    "    bottom, _ = axes.get_ylim()\n",
    "    top_pad = 1 * ((control_value - bottom) / 100)\n",
    "    if kwargs.get('control_label'):\n",
    "        axes.text(right - right_pad, control_value - top_pad, kwargs.get('control_label'), \n",
    "                  horizontalalignment='right', verticalalignment='top', color='red')\n",
    "    else:\n",
    "        axes.text(right - right_pad, control_value + - top_pad, 'Control', \n",
    "                  horizontalalignment='right', verticalalignment='top', color='red')\n",
    "    # Save the file\n",
    "    if kwargs.get('filename'):\n",
    "        fig.savefig(fname=kwargs.get('filename'), dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_data_scatter(x_key, y_key, results, control, exp_type, filter_params={}, \n",
    "               control_params=None, **kwargs):\n",
    "    filter_params[x_key] = None  # Set the X value to none for X-axis\n",
    "    \n",
    "    if not control_params:\n",
    "        control_params = dict([(key, None) for key in exp_type._fields])\n",
    "    filtered_control = filter_experiments(control.keys(), exp_type(**control_params))\n",
    "    processed_control = []\n",
    "    for exp in filtered_control:\n",
    "        exp_data = control[exp]\n",
    "        exp_data = list(map(lambda x: float(x), \n",
    "                            filter(lambda x: x, map(lambda x: x.get(y_key), exp_data))))\n",
    "        exp_mean, exp_ci = mean_confidence_interval(exp_data)\n",
    "        \n",
    "        processed_control.append((exp_mean, exp_ci))\n",
    "    \n",
    "    filtered_results = filter_experiments(results.keys(), exp_type(**filter_params))\n",
    "    processed_results = []\n",
    "    for exp in filtered_results:\n",
    "        exp_data = results[exp]\n",
    "        exp_data = list(map(lambda x: float(x), \n",
    "                            filter(lambda x: x, map(lambda x: x.get(y_key), exp_data))))\n",
    "        processed_results.append((getattr(exp, x_key), (exp_data)))\n",
    "    \n",
    "    # Sort the x axis in ascending order\n",
    "    processed_results = sorted(processed_results, key=lambda x: x[0])\n",
    "    control_value = processed_control[0][0]\n",
    "    \n",
    "    # Graph the data\n",
    "    figsize = kwargs.get('figsize', (15, 10))\n",
    "    fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    x_axis = []\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for x, y in processed_results:\n",
    "        x_axis.append(x)\n",
    "        x_data += ([x] * len(y))\n",
    "        y_data += y\n",
    "    \n",
    "    x_ok = []\n",
    "    x_anom = []\n",
    "    y_ok = []\n",
    "    y_anom = []\n",
    "    \n",
    "    data_dict = dict(processed_results)\n",
    "    for index, val in enumerate(y_data):\n",
    "        x = x_data[index]\n",
    "        raw_data = data_dict[x]\n",
    "        \n",
    "        mean = np.mean(raw_data)\n",
    "        std = np.std(raw_data)\n",
    "    \n",
    "        if (mean - 1 * std) < val < (mean + 1 * std):\n",
    "            x_ok.append(x)\n",
    "            y_ok.append(val)\n",
    "        else:\n",
    "            x_anom.append(x)\n",
    "            y_anom.append(val)\n",
    "            \n",
    "        \n",
    "    axes.set_xticks(x_axis)\n",
    "    axes.grid(linestyle='--')\n",
    "    axes.scatter(x_ok, y_ok, c='seagreen', label='within 1 std. dev')\n",
    "    axes.scatter(x_anom, y_anom, c='orangered', label='outside 1 std. dev')\n",
    "    axes.axhline(control_value, color='blue', linestyle='--')\n",
    "    legend_loc = kwargs.get('legend_loc', 'upper left')\n",
    "    axes.legend(loc=legend_loc)\n",
    "    # Config via. KWargs\n",
    "    if kwargs.get('figtitle'):\n",
    "        fig.suptitle(kwargs.get('figtitle'))\n",
    "    if kwargs.get('xlabel'):\n",
    "        axes.set_xlabel(kwargs.get('xlabel'))\n",
    "    if kwargs.get('ylabel'):\n",
    "        axes.set_ylabel(kwargs.get('ylabel'))\n",
    "    if kwargs.get('title'):\n",
    "        axes.set_title(kwargs.get('title'))\n",
    "    if kwargs.get('ylim'):\n",
    "        axes.set_ylim(*kwargs.get('ylim'))\n",
    "    if kwargs.get('xlim'):\n",
    "        axes.set_xlim(*kwargs.get('xlim'))\n",
    "    # Control label padding\n",
    "    left, right = axes.get_xlim()\n",
    "    right_pad = 1 * ((right - left) / 100)\n",
    "    bottom, _ = axes.get_ylim()\n",
    "    top_pad = 1 * ((control_value - bottom) / 100)\n",
    "    if kwargs.get('control_label'):\n",
    "        axes.text(right - right_pad, control_value + top_pad, kwargs.get('control_label'), \n",
    "                  horizontalalignment='right', verticalalignment='bottom', color='blue')\n",
    "    else:\n",
    "        axes.text(right - right_pad, control_value + top_pad, 'Control', \n",
    "                  horizontalalignment='right', verticalalignment='bottom', color='blue')\n",
    "    # Save the file\n",
    "    if kwargs.get('filename'):\n",
    "        fig.savefig(fname=kwargs.get('filename'), dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rime Multi-hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RmhExperiment = namedtuple('RmhExperiment', ['d', 'n', 't'])\n",
    "\n",
    "rmh_base_dir = Path('tpwsn-rmh/')\n",
    "rmh_results_dir = Path(rmh_base_dir, 'results-21x21')\n",
    "rmh_experiments_path = Path(rmh_results_dir, 'results_data.pickle')\n",
    "rmh_control_path = Path(rmh_results_dir, 'control_data-grace-01.pickle')\n",
    "rmh_graphs_dir = Path('graphs-21x21/rmh/')\n",
    "\n",
    "rmh_control, rmh_experiments = aggregate_results(rmh_results_dir)\n",
    "    \n",
    "if not rmh_graphs_dir.exists():\n",
    "    rmh_graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# Load other results from disk\n",
    "rmh_control_raw_dir = Path(rmh_base_dir, 'control-exp')\n",
    "rmh_stats_raw = [parse_control(str(Path(rmh_control_raw_dir, x, 'COOJA.testlog'))) for x in \n",
    "                 os.listdir(str(rmh_control_raw_dir))]\n",
    "\n",
    "# Get the average end tick time\n",
    "rmh_stats_raw = [x for x in rmh_stats_raw if x]\n",
    "rmh_stats_raw += [x.get('end_tick') for x in rmh_control[RmhExperiment(d=0, n=0, t='none')]]\n",
    "\n",
    "rmh_control_end_mean, rmh_control_end_ci = mean_confidence_interval(rmh_stats_raw)\n",
    "rmh_control_end_mean/1e6, rmh_control_end_ci/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmh_failure_modes = ('location', 'random')\n",
    "rmh_conc_failure_range = (1, 3, 5, 7, 9, 11, 13, 15)\n",
    "rmh_recovery_delay_range = (1, 3, 5, 7, 9, 11, 13, 15)\n",
    "    \n",
    "rmh_conc_failure_graphs = list(product(rmh_failure_modes, rmh_conc_failure_range))\n",
    "rmh_recovery_delay_graphs = list(product(rmh_failure_modes, rmh_recovery_delay_range))\n",
    "\n",
    "for failure_mode, conc_fails in rmh_conc_failure_graphs:\n",
    "    graph_filename = f'rmh-coverage-vs-delay-{failure_mode}-n={conc_fails}.eps'\n",
    "    graph_scatter_filename = f'rmh-coverage-vs-delay-{failure_mode}-n={conc_fails}-scatter.eps'\n",
    "    graph_file_path = Path(rmh_graphs_dir, graph_filename)\n",
    "    graph_scatter_file_path = Path(rmh_graphs_dir, graph_scatter_filename)\n",
    "    \n",
    "    graph_data('d', 'coverage', rmh_experiments, rmh_control, RmhExperiment, \n",
    "               filter_params = {\n",
    "                   't': failure_mode,\n",
    "                   'n': conc_fails\n",
    "               }, xlabel='Mote recovery delay (s)', ylabel='Message coverage (%)',\n",
    "               control_label='0 fail control', figsize=(6, 4),\n",
    "               ylim=(0, 105), filename=str(graph_file_path))\n",
    "    \n",
    "    graph_data_scatter('d', 'coverage', rmh_experiments, rmh_control, RmhExperiment, \n",
    "                       filter_params = {\n",
    "                           't': failure_mode,\n",
    "                           'n': conc_fails\n",
    "                       }, xlabel='Mote recovery delay (s)', ylabel='Message coverage (%)',\n",
    "                       control_label='0 fail control', figsize=(6, 4), legend_loc='best',\n",
    "                       ylim=(-5, 105), filename=str(graph_scatter_file_path))\n",
    "    \n",
    "for failure_mode, recovery_delay in rmh_recovery_delay_graphs:\n",
    "    graph_filename = f'rmh-coverage-vs-conc-fails-{failure_mode}-d={recovery_delay}.eps'\n",
    "    graph_scatter_filename = f'rmh-coverage-vs-conc-fails-{failure_mode}-d={recovery_delay}-scatter.eps'\n",
    "    graph_file_path = Path(rmh_graphs_dir, graph_filename)\n",
    "    graph_scatter_file_path = Path(rmh_graphs_dir, graph_scatter_filename)\n",
    "    \n",
    "    graph_data('n', 'coverage', rmh_experiments, rmh_control, RmhExperiment, \n",
    "               filter_params = {\n",
    "                   't': failure_mode,\n",
    "                   'd': recovery_delay\n",
    "               }, xlabel='Maximum concurrent failures (motes)', ylabel='Message coverage (%)',\n",
    "               control_label='0 fail control', figsize=(6, 4),\n",
    "               ylim=(0, 105), filename=str(graph_file_path))\n",
    "    \n",
    "    graph_data_scatter('n', 'coverage', rmh_experiments, rmh_control, RmhExperiment, \n",
    "                       filter_params = {\n",
    "                           't': failure_mode,\n",
    "                           'd': recovery_delay\n",
    "                       }, xlabel='Maximum concurrent failures (motes)', ylabel='Message coverage (%)',\n",
    "                       control_label='0 fail control', figsize=(6, 4), legend_loc='best',\n",
    "                       ylim=(-5, 105), filename=str(graph_scatter_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(namedtuple('Experiment', ['d', 'k', 'imin', 'n', 't', 'imax'])):\n",
    "    __slots__ = ()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.d}-{self.k}-{self.imin}-{self.imax}-{self.n}-{self.t}'\n",
    "\n",
    "trickle_base_dir = Path('tpwsn-trickle/')\n",
    "trickle_results_dir = Path(trickle_base_dir, 'results-21x21')\n",
    "trickle_experiments_path = Path(trickle_base_dir, 'results_data.pickle')\n",
    "trickle_control_path = Path(trickle_base_dir, 'control_data.pickle')\n",
    "trickle_graphs_dir = Path('graphs-21x21/trickle/')\n",
    "\n",
    "trickle_control, trickle_experiments = aggregate_results(trickle_results_dir)\n",
    "\n",
    "if not trickle_graphs_dir.exists():\n",
    "    trickle_graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# dict([(key, None) for key in Experiment._fields])\n",
    "trickle_control_key = list(filter_experiments(trickle_control.keys(), Experiment(**{\n",
    "    'k': 2,\n",
    "    'imin': 16, \n",
    "    'imax': 10, \n",
    "    'd': None, \n",
    "    'n': None,\n",
    "    't': None\n",
    "})))[0]\n",
    "trickle_control_end_mean, trickle_control_end_ci = mean_confidence_interval(\n",
    "    [x.get('end_tick') for x in trickle_control[trickle_control_key]])\n",
    "trickle_control_end_mean/1e6, trickle_control_end_ci/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trickle_failure_modes = ('location', 'random')\n",
    "trickle_conc_failure_range = (1, 3, 5, 7, 9, 11, 13, 15)\n",
    "trickle_recovery_delay_range = (1, 3, 5, 7, 9, 11, 13, 15)\n",
    "\n",
    "trickle_conc_failure_graphs = product(trickle_failure_modes, trickle_conc_failure_range)\n",
    "trickle_recovery_delay_graphs = product(trickle_failure_modes, trickle_recovery_delay_range)\n",
    "\n",
    "for failure_mode, conc_fails in trickle_conc_failure_graphs:\n",
    "    graph_filename = f'trickle-coverage-vs-delay-{failure_mode}-n={conc_fails}.eps'\n",
    "    graph_scatter_filename = f'trickle-coverage-vs-delay-{failure_mode}-n={conc_fails}-scatter.eps'\n",
    "    graph_file_path = Path(trickle_graphs_dir, graph_filename)\n",
    "    graph_scatter_file_path = Path(trickle_graphs_dir, graph_scatter_filename)\n",
    "    \n",
    "    graph_data('d', 'coverage', trickle_experiments, trickle_control, Experiment, \n",
    "               filter_params = {\n",
    "                   't': failure_mode,\n",
    "                   'n': conc_fails,\n",
    "                   'k': 2,\n",
    "                   'imin': 16,\n",
    "                   'imax': 10,\n",
    "               }, xlabel='Mote recovery delay (s)', ylabel='Message coverage (%)',\n",
    "               control_label='0 fail control', figsize=(6, 4), ylim=(0, 105),\n",
    "               filename=str(graph_file_path))\n",
    "    \n",
    "    graph_data_scatter('d', 'coverage', trickle_experiments, trickle_control, Experiment, \n",
    "                       filter_params = {\n",
    "                           't': failure_mode,\n",
    "                           'n': conc_fails,\n",
    "                           'k': 2,\n",
    "                           'imin': 16,\n",
    "                           'imax': 10,\n",
    "                       }, xlabel='Mote recovery delay (s)', ylabel='Message coverage (%)',\n",
    "                       control_label='0 fail control', figsize=(6, 4), ylim=(-5, 110),\n",
    "                       filename=str(graph_scatter_file_path), legend_loc='best')\n",
    "    \n",
    "for failure_mode, recovery_delay in trickle_recovery_delay_graphs:\n",
    "    graph_filename = f'trickle-coverage-vs-conc-fails-{failure_mode}-d={recovery_delay}.eps'\n",
    "    graph_scatter_filename = f'trickle-coverage-vs-conc-fails-{failure_mode}-d={recovery_delay}-scatter.eps'\n",
    "    graph_file_path = Path(trickle_graphs_dir, graph_filename)\n",
    "    graph_scatter_file_path = Path(trickle_graphs_dir, graph_scatter_filename)\n",
    "    \n",
    "    graph_data('n', 'coverage', trickle_experiments, trickle_control, Experiment, \n",
    "               filter_params = {\n",
    "                   't': failure_mode,\n",
    "                   'd': recovery_delay,\n",
    "                   'k': 2,\n",
    "                   'imin': 16,\n",
    "                   'imax': 10,\n",
    "               }, xlabel='Maximum concurrent failures (motes)', ylabel='Message coverage (%)',\n",
    "               control_label='0 fail control', figsize=(6, 4), ylim=(0, 105),\n",
    "               filename=str(graph_file_path))\n",
    "    \n",
    "    graph_data_scatter('n', 'coverage', trickle_experiments, trickle_control, Experiment, \n",
    "                       filter_params = {\n",
    "                           't': failure_mode,\n",
    "                           'd': recovery_delay,\n",
    "                           'k': 2,\n",
    "                           'imin': 16,\n",
    "                           'imax': 10,\n",
    "                       }, xlabel='Maximum concurrent failures (motes)', ylabel='Message coverage (%)',\n",
    "                       control_label='0 fail control', figsize=(6, 4), ylim=(-5, 110),\n",
    "                       filename=str(graph_scatter_file_path), legend_loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trickle_experiments_raw = Path(trickle_base_dir, 'experiments')\n",
    "\n",
    "graph_file_path = Path(trickle_graphs_dir, 'test-cumilative-coverage.pdf')\n",
    "graph_coverage(trickle_experiments_raw, trickle_experiments, trickle_control, Experiment, \n",
    "               filter_params = {\n",
    "                   't': 'location',\n",
    "                   'd': 15,\n",
    "                   'k': 2,\n",
    "                   'imin': 16,\n",
    "                   'imax': 10,\n",
    "                   'n': 15,\n",
    "               }, figtitle=\"Cumulative message coverage of Trickle over time across 20 simulations\",\n",
    "               xlabel=\"Time (seconds)\", ylabel=\"Cumulative message coverage (% of motes)\", \n",
    "               plot_sims=True, legend_loc='lower right', filename=str(graph_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMH-Beaconing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmhb_base_dir = Path('tpwsn-rmh-beaconing/')\n",
    "rmhb_results_dir = Path(rmhb_base_dir, 'results-21x21')\n",
    "rmhb_experiments_path = Path(rmhb_results_dir, 'results_data.pickle')\n",
    "rmhb_control_path = Path(rmhb_results_dir, 'control_data-grace-01.pickle')\n",
    "rmhb_graphs_dir = Path('graphs-21x21/rmhb/')\n",
    "\n",
    "rmhb_control, rmhb_experiments = aggregate_results(rmhb_results_dir)\n",
    "    \n",
    "if not rmhb_graphs_dir.exists():\n",
    "    rmhb_graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# # Load other results from disk\n",
    "# rmhb_control_raw_dir = Path(rmhb_base_dir, 'control-exp')\n",
    "# rmhb_stats_raw = [parse_control(str(Path(rmhb_control_raw_dir, x, 'COOJA.testlog'))) for x in \n",
    "#                  os.listdir(str(rmhb_control_raw_dir))]\n",
    "# # Get the average end tick time\n",
    "# rmhb_stats_raw = [x for x in rmhb_stats_raw if x]\n",
    "# rmhb_stats_raw += [x.get('end_tick') for x in rmhb_control[RmhExperiment(d=0, n=0, t='none')]]\n",
    "\n",
    "# rmhb_control_end_mean, rmhb_control_end_ci = mean_confidence_interval(rmhb_stats_raw)\n",
    "# rmhb_control_end_mean/1e6, rmhb_control_end_ci/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmhb_failure_modes = ('location', 'random')\n",
    "rmhb_conc_failure_range = (1, 3, 5, 7, 9, 11, 13, 15)\n",
    "rmhb_recovery_delay_range = (1, 3, 5, 7, 9, 11, 13, 15)\n",
    "    \n",
    "rmhb_conc_failure_graphs = list(product(rmhb_failure_modes, rmhb_conc_failure_range))\n",
    "rmhb_recovery_delay_graphs = list(product(rmhb_failure_modes, rmhb_recovery_delay_range))\n",
    "\n",
    "for failure_mode, conc_fails in rmhb_conc_failure_graphs:\n",
    "    graph_filename = f'rmhb-coverage-vs-delay-{failure_mode}-n={conc_fails}.eps'\n",
    "    graph_scatter_filename = f'rmhb-coverage-vs-delay-{failure_mode}-n={conc_fails}-scatter.eps'\n",
    "    graph_file_path = Path(rmhb_graphs_dir, graph_filename)\n",
    "    graph_scatter_file_path = Path(rmhb_graphs_dir, graph_scatter_filename)\n",
    "    \n",
    "    graph_data('d', 'coverage', rmhb_experiments, rmhb_control, RmhExperiment, \n",
    "               filter_params = {\n",
    "                   't': failure_mode,\n",
    "                   'n': conc_fails\n",
    "               }, xlabel='Mote recovery delay (s)', ylabel='Message coverage (%)',\n",
    "               control_label='0 fail control', figsize=(6, 4),\n",
    "               ylim=(0, 105), filename=str(graph_file_path))\n",
    "    \n",
    "    graph_data_scatter('d', 'coverage', rmhb_experiments, rmhb_control, RmhExperiment, \n",
    "                       filter_params = {\n",
    "                           't': failure_mode,\n",
    "                           'n': conc_fails\n",
    "                       }, xlabel='Mote recovery delay (s)', ylabel='Message coverage (%)',\n",
    "                       control_label='0 fail control', figsize=(6, 4), legend_loc='best',\n",
    "                       ylim=(-5, 105), filename=str(graph_scatter_file_path))\n",
    "    \n",
    "for failure_mode, recovery_delay in rmhb_recovery_delay_graphs:\n",
    "    graph_filename = f'rmhb-coverage-vs-conc-fails-{failure_mode}-d={recovery_delay}.eps'\n",
    "    graph_scatter_filename = f'rmhb-coverage-vs-conc-fails-{failure_mode}-d={recovery_delay}-scatter.eps'\n",
    "    graph_file_path = Path(rmhb_graphs_dir, graph_filename)\n",
    "    graph_scatter_file_path = Path(rmhb_graphs_dir, graph_scatter_filename)\n",
    "    \n",
    "    graph_data('n', 'coverage', rmhb_experiments, rmhb_control, RmhExperiment, \n",
    "               filter_params = {\n",
    "                   't': failure_mode,\n",
    "                   'd': recovery_delay\n",
    "               }, xlabel='Maximum concurrent failures (motes)', ylabel='Message coverage (%)',\n",
    "               control_label='0 fail control', figsize=(6, 4),\n",
    "               ylim=(0, 105), filename=str(graph_file_path))\n",
    "    \n",
    "    graph_data_scatter('n', 'coverage', rmhb_experiments, rmhb_control, RmhExperiment, \n",
    "                       filter_params = {\n",
    "                           't': failure_mode,\n",
    "                           'd': recovery_delay\n",
    "                       }, xlabel='Maximum concurrent failures (motes)', ylabel='Message coverage (%)',\n",
    "                       control_label='0 fail control', figsize=(6, 4), legend_loc='best',\n",
    "                       ylim=(-5, 105), filename=str(graph_scatter_file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
